{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cfc0f48-cb44-4a2a-80d2-aa22449b31af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generating Text\n",
    "\n",
    "Let's explore how to send a simple prompt and get Gemini to return text!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8091526-eb71-410b-b97a-d6fd5b234a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcee58c5-e7a2-41f8-89d4-2b52b8b2ad45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Trying Gemini API\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b0849d-7386-47bd-989e-70c5ae5d663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca6162-80d8-4fef-bf13-6ec0fd64a1a6",
   "metadata": {},
   "source": [
    "# `gemini-pro` Text and Single Response API Call\n",
    "\n",
    "To start, let's ask a simple question. First, we'll create a `GenerativeModel` object, which tells Gemini which model to use. For text-based questions and answers, as well as chats, we'll use **gemini-pro**, a model designed for general _text-based_ tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cebe1227-52ec-4a63-8f26-22f420188026",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fed70d-a981-4357-a204-3377dce564c1",
   "metadata": {},
   "source": [
    "To communicate our prompts to Gemini's backend, we'll utilize the `model.generate_content('prompt')` function. This function handles diverse prompt types and use cases, such as text-only, text+image, and chatbot interactions, depending on the model linked to it.\n",
    "\n",
    "You can find the full documentation of `model.generate_content()` [here](https://ai.google.dev/api/python/google/generativeai/GenerativeModel).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55647806-1c4e-434a-ada4-c55727109c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What's the capital of India?\"\n",
    "response = model.generate_content(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e44bdb-a6d6-44f1-a1fb-f30f5100bb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.generativeai.types.generation_types.GenerateContentResponse"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73677210-6279-41ef-a870-adeb429ca236",
   "metadata": {},
   "source": [
    "In this case the result can be accessed via `reponse.text`. The status is stored within `response.prompt_feedback`.<br />\n",
    "If multiple responses have beed created you can inspect them using `response.candidates`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7908d36-af84-4e7d-8e09-91955560e172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c241b6c8-fae0-4397-a763-c07218855e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.prompt_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9824bec5-7f7a-4040-989c-28f41c330e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[index: 0\n",
      "content {\n",
      "  parts {\n",
      "    text: \"New Delhi\"\n",
      "  }\n",
      "  role: \"model\"\n",
      "}\n",
      "finish_reason: STOP\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HATE_SPEECH\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_HARASSMENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "safety_ratings {\n",
      "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "  probability: NEGLIGIBLE\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(response.candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf194ad-2552-4793-a63c-69eb6b6c2f37",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ddc9e-7a34-4b16-be8a-1a1b22ab4680",
   "metadata": {},
   "source": [
    "Let's try another, more creative prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7177b68-2598-4b40-a70b-4002f39c727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo, listen up, it's time to drop some rhymes,\n",
      "About a mischievous kid, he's one of a kind.\n",
      "Shinchan Nohara, he's got the moves and the flow,\n",
      "His antics and energy are like a raging show.\n",
      "\n",
      "He's got a crew, like D and Boo, they're always down,\n",
      "Causing trouble and turning the whole town upside-down.\n",
      "With a voice that's high-pitched, and a head full of hair,\n",
      "Shinchan's like a walking, talking dare.\n",
      "\n",
      "He's got bars that hit like Mike Tyson's punches,\n",
      "Leaving adults dizzy, they can't handle his lunches.\n",
      "He's got a mind like a steel trap, sharp and keen,\n",
      "Always finding ways to make a scene.\n",
      "\n",
      "He's like Eminem, spitting truth and fire,\n",
      "Igniting laughter and setting hearts afire.\n",
      "His lyrics are clever, his delivery is raw,\n",
      "Shinchan's the real deal, he's got the whole world in awe.\n",
      "\n",
      "From Kasukabe to the world, he's spreading joy,\n",
      "With his crazy antics and his mischievous ploy.\n",
      "He's a force of nature, a whirlwind of fun,\n",
      "Shinchan Nohara, he's second to none.\n",
      "\n",
      "So let's all raise our hands and give him a cheer,\n",
      "For Shinchan, the kid who brings us endless cheer.\n",
      "He's the rap sensation, the next big thing,\n",
      "Shinchan's the king, and his reign will never end.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a short rap about Shinchan with lots of Eminem references, and make sure it rhymes\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e082146-eb14-4108-bffa-c05476db63c7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Remember to save time, you could make this a function yourself:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cec6dc89-a720-4767-8c6e-f4b33a8d9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_response(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eeb476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
